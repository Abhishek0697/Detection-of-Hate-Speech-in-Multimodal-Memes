{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Unimodal Analysis - ResNeXt101_32x8d.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishek0697/Detection-of-Hate-Speech-in-Multimodal-Memes/blob/main/Code/Experiments/ResNeXt101_32x8d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "UxKFUPgdCkoo"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS6Heny2Ckou"
      },
      "source": [
        "'''IMPORTING NECESSARY MODULES\n",
        "'''\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "sys.path.append('./Trainers/')\n",
        "sys.path.append('./Dataloaders/')\n",
        "sys.path.append('./utils/')\n",
        "sys.path.append('./architectures/')\n",
        "\n",
        "from dataloader import mydataset, create_prime_dict \n",
        "from trainer_ResNet import train, test_classify\n",
        "from resnet_models import ResNet,Bottleneck,resnext101_32x8d\n",
        "from Load_model import load\n",
        "from plot_curves import plot_loss, plot_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkTFK5d-Ckov",
        "outputId": "f8d03279-9e50-43cc-b834-03eef6524ace"
      },
      "source": [
        "device = torch.device('cuda:6' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i7pBbm_Ckow"
      },
      "source": [
        "**Dataloading Scheme**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBg3I5zsCkox"
      },
      "source": [
        "trainlist = 'add path of training list'\n",
        "validlist = 'add path of validation list'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN9g2Wh4Ckoy",
        "outputId": "f3f663ea-3e19-4e59-f350-8b9815479a17"
      },
      "source": [
        "prime_dict = create_prime_dict(trainlist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of classes =  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrqSFkjdCkoz"
      },
      "source": [
        "'''Train Dataloader''' \n",
        "train_dataset = mydataset(trainlist, prime_dict, name='train')          \n",
        "train_dataloader = data.DataLoader(train_dataset, shuffle= True, batch_size = 128, num_workers=16,pin_memory=True)\n",
        "\n",
        "\n",
        "'''Validation Dataloader''' \n",
        "validation_dataset = mydataset(validlist, prime_dict, name='valid')         \n",
        "validation_dataloader = data.DataLoader(validation_dataset, shuffle=False, batch_size = 32, num_workers=16,pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYvArnlbCko0"
      },
      "source": [
        "**Model Definition**\n",
        "\n",
        "Train Resnet50/ ResNext101"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYbW-9FOCko0"
      },
      "source": [
        "modelname = 'ResneXt101_32x8d'\n",
        "modelpath = './saved_model_checkpoints/'+modelname"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gFdj_eCCko1"
      },
      "source": [
        "# model = ResNet(Bottleneck, [3, 4, 6, 3], num_classes = 2)\n",
        "\n",
        "\n",
        "'''\n",
        "Pretrained ResNeXt101_32x8d\n",
        "'''\n",
        "model = resnext101_32x8d(pretrained = True)\n",
        "\n",
        "\n",
        "model = nn.DataParallel(model,device_ids=[6,7]).to(device)\n",
        "model\n",
        "\n",
        "\n",
        "# '''\n",
        "# Load saved model from checkpoint\n",
        "# '''\n",
        "# model, optimizer, lr_scheduler, train_loss, v_loss, v_acc, epoch = load(modelpath, model, optimizer, lr_scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmD_vszbCko2"
      },
      "source": [
        "'''\n",
        "Transfer Learning\n",
        "'''\n",
        "\n",
        "# for param in model.module.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "fc_inputs = model.module.fc.in_features\n",
        "\n",
        "model.module.fc = nn.Sequential(\n",
        "    nn.Linear(fc_inputs, 2)\n",
        "#     nn.BatchNorm1d(4096),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Linear(768, 2)\n",
        "    \n",
        ")\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amj26Zm9Cko3"
      },
      "source": [
        "**Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0D-_wCDCko4"
      },
      "source": [
        "## Loss Function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4, momentum=0.9)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 20, gamma = 0.1)\n",
        "\n",
        "# Epochs\n",
        "num_Epochs = 80"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb_sxW8VCko4"
      },
      "source": [
        "writer = SummaryWriter(\"ResNeXt101_32x8d\")\n",
        "\n",
        "train(model, train_dataloader, validation_dataloader, criterion, optimizer, lr_scheduler, modelpath, writer, device, epochs = num_Epochs)\\\n",
        "\n",
        "writer.flush()\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBwlfv5nCko5"
      },
      "source": [
        "'''\n",
        "Load saved model from checkpoint\n",
        "'''\n",
        "model, optimizer, lr_scheduler, train_loss, v_loss, v_acc, epoch = load(modelpath, model, optimizer, lr_scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3amO7aogCko6"
      },
      "source": [
        "**Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "04ciej8cCko6",
        "outputId": "202eb3f6-bb53-423b-d605-928057e7d7e6"
      },
      "source": [
        "test_classify(model, validation_dataloader, criterion, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7325438114110836, 0.5090180360721442)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwM6JanVCko8",
        "outputId": "48bad12c-3537-4514-969d-995e88a60c52"
      },
      "source": [
        "avg_loss = 0\n",
        "\n",
        "for batch_num, (feats, captions, input_id, attention_masks, target) in enumerate(train_dataloader):\n",
        "        feats, target = feats.to(device), target.to(device)\n",
        "\n",
        "\n",
        "        '''\n",
        "        Compute output and Loss\n",
        "        '''\n",
        "        output, embeddings = model(feats) \n",
        "        total_loss = criterion(output, target)\n",
        "        \n",
        "        \n",
        "        avg_loss += total_loss.item()\n",
        "        \n",
        "        \n",
        "avg_loss/len(train_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6497447961255124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQG8TRmTCko8",
        "outputId": "5316053d-7acc-4819-cd31-9b2b0df1706d"
      },
      "source": [
        "'''\n",
        "Scale of embeddings\n",
        "'''\n",
        "embeddings[0][0:100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.2928e-02, -2.5917e-04, -7.6083e-03, -2.3284e-02, -1.7803e-02,\n",
              "        -1.1721e-02, -1.4128e-02, -3.9467e-03,  6.5848e-03, -4.5360e-03,\n",
              "        -5.9023e-03, -2.7679e-02, -1.8074e-02,  2.7270e-03, -1.8123e-02,\n",
              "        -2.0154e-02,  1.9357e-03, -1.4437e-02, -2.0706e-02, -4.4435e-02,\n",
              "         2.3793e-02,  1.9012e-03, -1.5128e-02, -2.1997e-02, -1.7046e-02,\n",
              "         1.6173e-03, -1.6588e-02,  3.5790e-02,  2.8867e-03, -2.5260e-02,\n",
              "        -1.3732e-02, -8.6504e-03, -1.4730e-02, -1.7183e-02, -1.4189e-02,\n",
              "        -2.1576e-03, -1.1566e-02, -2.0425e-05, -9.7702e-03, -1.0505e-02,\n",
              "        -2.9042e-02, -3.8561e-03, -5.6513e-03, -1.2800e-02,  4.6991e-04,\n",
              "        -2.6957e-03,  2.3134e-03, -2.1837e-02, -1.2266e-02,  6.1447e-04,\n",
              "        -3.7410e-03, -1.0256e-02, -2.3636e-03, -4.2802e-02,  3.3450e-02,\n",
              "        -1.0314e-02, -4.2708e-03,  1.0251e-03,  1.9456e-02, -2.2669e-02,\n",
              "        -1.3707e-02,  5.0964e-03,  1.7879e-03, -2.2759e-02,  2.6169e-03,\n",
              "        -4.8373e-02, -2.1960e-03, -2.8194e-02, -1.3670e-02,  1.8859e-03,\n",
              "        -1.9725e-03, -5.2208e-03, -1.5466e-02, -2.4133e-02, -1.2710e-02,\n",
              "        -1.8952e-02, -1.2269e-03, -1.3496e-02,  2.3106e-02,  4.7452e-03,\n",
              "         3.5954e-03, -1.1792e-02, -3.4582e-04, -2.1002e-03,  8.5951e-03,\n",
              "        -1.3682e-02, -1.4102e-02,  1.7165e-03, -3.8034e-02, -3.3327e-02,\n",
              "        -1.0200e-02,  3.3577e-03,  1.9891e-02, -1.2890e-02, -1.7060e-02,\n",
              "         1.5868e-03, -2.0351e-02, -1.8340e-02,  6.6969e-04, -8.6881e-03],\n",
              "       device='cuda:6', grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJV0jhMFCko9",
        "outputId": "339014b5-7de8-4218-a741-60095807a411"
      },
      "source": [
        "'''\n",
        "Scale of output\n",
        "'''\n",
        "output[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.2626, -0.2895], device='cuda:6', grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}