{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "BERT+ResNeXt+Image_Captioning.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishek0697/Detection-of-Hate-Speech-in-Multimodal-Memes/blob/main/Code/Experiments/BERT%2BResNeXt%2BImage_Captioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fNxB0trzaP8i"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAbMlndnaP8k"
      },
      "source": [
        "'''\n",
        "IMPORTING NECESSARY MODULES\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "sys.path.append('./Trainers/')\n",
        "sys.path.append('./Dataloaders/')\n",
        "sys.path.append('./utils/')\n",
        "sys.path.append('./architectures/')\n",
        "\n",
        "from dataloader import mydataset_captioning, mytestdataset\n",
        "from Load_model import load\n",
        "from plot_curves import plot_loss, plot_acc\n",
        "from trainer_Resnet_BERT_Captioning import train, test_classify\n",
        "\n",
        "'''\n",
        "For ResNeXt\n",
        "'''\n",
        "from resnet_models import ResNet,Bottleneck, resnext101_32x8d\n",
        "\n",
        "'''\n",
        "For BERT\n",
        "'''\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHfFe7WDaP8k"
      },
      "source": [
        "**Device**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFeNpEoAaP8k"
      },
      "source": [
        "gpu_ids = [7,6]\n",
        "device = torch.device('cuda:'+ str(gpu_ids[0]) if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9tV3N_haP8l"
      },
      "source": [
        "**Dataloading Scheme**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBPb5OqiaP8l"
      },
      "source": [
        "trainlist = 'add path of training list'\n",
        "validlist = 'add path of validation list'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYE7ZWHgaP8l"
      },
      "source": [
        "'''\n",
        "Train Dataloader\n",
        "''' \n",
        "train_dataset = mydataset_captioning(trainlist, name='train')          \n",
        "train_dataloader = data.DataLoader(train_dataset, shuffle= True, batch_size = 32, num_workers=16,pin_memory=True)\n",
        "\n",
        "\n",
        "'''\n",
        "Validation Dataloader\n",
        "''' \n",
        "validation_dataset = mydataset_captioning(validlist, name='valid')         \n",
        "validation_dataloader = data.DataLoader(validation_dataset, shuffle=False, batch_size = 32, num_workers=16,pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFqdxztfaP8m"
      },
      "source": [
        "**Model Definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxRnFreKaP8n"
      },
      "source": [
        "'''\n",
        "Model1 ResNeXt101_32x8d\n",
        "'''\n",
        "# Image_model = ResNet(Bottleneck, [3, 4, 6, 3], num_classes = 2)\n",
        "Image_model = resnext101_32x8d()\n",
        "\n",
        "Image_model.fc = nn.Sequential(\n",
        "    nn.Linear(Image_model.fc.in_features, 2)\n",
        "    )\n",
        "\n",
        "Image_model = nn.DataParallel(Image_model,device_ids = gpu_ids).to(device)\n",
        "\n",
        "\n",
        "'''\n",
        "Load saved model from checkpoint\n",
        "'''\n",
        "model1_name = 'ResneXt101_32x8d'\n",
        "model1_path = './saved_model_checkpoints/'+model1_name\n",
        "\n",
        "checkpoint1 = torch.load(model1_path)\n",
        "Image_model.load_state_dict(checkpoint1['model_state_dict'])\n",
        "Image_model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AyJYW6haP8n"
      },
      "source": [
        "'''\n",
        "Model 2 BERT\n",
        "\n",
        "Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top.\n",
        "''' \n",
        "\n",
        "Text_model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 2,   \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = True\n",
        ")\n",
        "\n",
        "Text_model = nn.DataParallel(Text_model,device_ids=gpu_ids).to(device)\n",
        "\n",
        "\n",
        "'''\n",
        "Load saved model from checkpoint\n",
        "'''\n",
        "model2_name = 'BERT_basic'\n",
        "model2_path = './saved_model_checkpoints/'+model2_name\n",
        "\n",
        "checkpoint2 = torch.load(model2_path)\n",
        "Text_model.load_state_dict(checkpoint2['model_state_dict'])\n",
        "\n",
        "Text_model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3VLQHnuaP8o"
      },
      "source": [
        "'''\n",
        "Fusion \n",
        "Image Features, Text Features and Captions generated by our Captioning model\n",
        "'''\n",
        "class FusionNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_classes, drop_prob = 0.1):\n",
        "        super(FusionNet, self).__init__()\n",
        "        \n",
        "        self.concat = nn.Linear(in_features=768+2048+768, out_features= 512)\n",
        "        \n",
        "        self.bn = nn.BatchNorm1d(512)\n",
        "        self.bn1 = nn.BatchNorm1d(768)\n",
        "        self.bn2 = nn.BatchNorm1d(2048)\n",
        "        self.bn3 = nn.BatchNorm1d(768)\n",
        "\n",
        "        \n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        \n",
        "        self.classify = nn.Linear(in_features = 512, out_features = num_classes)\n",
        "        \n",
        "        \n",
        "    def forward(self, text_features, image_features, caption_features):\n",
        "\n",
        "        text_features = self.bn1(text_features)\n",
        "        image_features = self.bn2(image_features)\n",
        "        caption_features = self.bn3(caption_features)\n",
        "\n",
        "        fused_input =  torch.cat((text_features, image_features, caption_features), dim=1)\n",
        "        \n",
        "        x = self.concat(fused_input)\n",
        "        x = F.relu(self.bn(x))        \n",
        "        \n",
        "        x = F.relu(self.classify(x)) \n",
        "\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85pRXktUaP8o"
      },
      "source": [
        "Fusion_model = FusionNet(num_classes = 2 , drop_prob = 0.1)\n",
        "Fusion_model = nn.DataParallel(Fusion_model, device_ids=gpu_ids).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdt6fL6-aP8o"
      },
      "source": [
        "**Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC_FZ5uCaP8o"
      },
      "source": [
        "'''\n",
        "Loss Function\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "'''\n",
        "Optimizer\n",
        "'''\n",
        "optimizer = torch.optim.SGD(Fusion_model.parameters(), lr=0.1, weight_decay=1e-4, momentum=0.9)\n",
        "# optimizer = AdamW(Fusion_model.parameters(), lr = 2e-3, eps = 1e-8)\n",
        "\n",
        "\n",
        "'''\n",
        "Number of training epochs.\n",
        "'''\n",
        "num_Epochs = 10\n",
        "\n",
        "\n",
        "# '''\n",
        "# OneCycleLR\n",
        "# '''\n",
        "# max_lr = 0.05\n",
        "# lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, total_steps=None, epochs=num_Epochs, steps_per_epoch=len(train_dataloader), pct_start=0.3, anneal_strategy='cos', cycle_momentum=True, base_momentum=0.85, max_momentum=0.95, div_factor=25.0, final_div_factor=10000.0, last_epoch=-1)\n",
        "\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 4, gamma = 0.001)\n",
        "\n",
        "# lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agClo63KaP8p"
      },
      "source": [
        "model_name = 'ImageCaptioning'\n",
        "model_path = '.saved_model_checkpoints/'+model_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJUzH2BIaP8p"
      },
      "source": [
        "writer = SummaryWriter(model_name)\n",
        "\n",
        "train(Image_model, Text_model, Fusion_model, train_dataloader, validation_dataloader, criterion, optimizer, lr_scheduler, model_path, writer, device, epochs = num_Epochs)\n",
        "\n",
        "writer.flush()\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL0-sKbkaP8p"
      },
      "source": [
        "'''\n",
        "Load saved model from checkpoint\n",
        "'''\n",
        "Fusion_model, optimizer, lr_scheduler, train_loss, v_loss, v_acc, epoch = load(model_path, Fusion_model, optimizer, lr_scheduler)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZY-h3UtaP8q"
      },
      "source": [
        "**Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LZVVQ-1aP8q"
      },
      "source": [
        "test_classify(Fusion_model, validation_dataloader, criterion, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzTSBs4SaP8q"
      },
      "source": [
        "**Predict on Test and generate output.csv**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQM4UyDkaP8r"
      },
      "source": [
        "**Test Dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHDvADPBaP8r"
      },
      "source": [
        "testlist = 'path of test set'\n",
        "\n",
        "test_dataset = mytestdataset(testlist, name='test')          \n",
        "test_dataloader = data.DataLoader(test_dataset, shuffle= False, batch_size = 32, num_workers=8,pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPoGZ1L0aP8r"
      },
      "source": [
        "from predict import predict\n",
        "predict(image_model, text_model, fusion_model, test_dataloader, device)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}